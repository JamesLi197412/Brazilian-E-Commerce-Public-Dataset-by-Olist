{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-13T08:17:31.218146Z",
     "start_time": "2024-02-13T08:17:31.211121Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /Users/jamesli/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import RSLPStemmer\n",
    "nltk.download('rslp')\n",
    "import string\n",
    "\n",
    "\n",
    "from data_process import master\n",
    "\n",
    "\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,confusion_matrix,f1_score\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "stopwords_pt = set(stopwords.words(\"portuguese\"))\n",
    "STOPWORDS = stopwords.words(\"portuguese\")\n",
    "\n",
    "\n",
    "# reference: https://github.com/CaptainE/RNN-LSTM-in-numpy/blob/master/RNN_LSTM_from_scratch.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Access to df\n",
    "df = master()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T08:04:39.813684Z",
     "start_time": "2024-02-13T08:02:58.496288Z"
    }
   },
   "id": "9431d7652cb05408"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7277068, 2)\n"
     ]
    }
   ],
   "source": [
    "df_review = df.loc[:,['review_score','review_comment_message']]\n",
    "# remove null data on certain column\n",
    "df_review = df_review.dropna(subset = ['review_comment_message'])\n",
    "df_review.columns = ['score','comment']\n",
    "\n",
    "print(f'Dataset shape: {df_review.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T08:05:04.738200Z",
     "start_time": "2024-02-13T08:04:39.819107Z"
    }
   },
   "id": "f8474953121f3999"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Give certain label to df_review\n",
    "# Basically split the table into positive or negative reivew\n",
    "df_review['label'] = np.where(df_review['score'] >=3, 1,0)\n",
    "\n",
    "# drop column score\n",
    "df_review.drop(columns = ['score'], inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T08:05:04.955643Z",
     "start_time": "2024-02-13T08:05:04.739122Z"
    }
   },
   "id": "f8019f8b1371ae67"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Option 1: Convert all portuguese into English and conduct processing\n",
    "def translate_text(text):\n",
    "    translated = GoogleTranslator(source='auto', target='en').translate(text)\n",
    "    return translated\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T08:05:04.963020Z",
     "start_time": "2024-02-13T08:05:04.956778Z"
    }
   },
   "id": "69a6d24683190dfa"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Pipelines & Custom Transformers in scikit-learn\n",
    "# Reference : https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156\n",
    "def remove_stopwords(text,stopwords_pt):\n",
    "    '''\n",
    "        Remove stopwords from reviews\n",
    "    :param texto: \n",
    "    :return: \n",
    "    '''\n",
    "    text = text.lower()\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords_pt]\n",
    "\n",
    "    text_clean = (\" \".join(filtered_words))\n",
    "\n",
    "\n",
    "    return text_clean\n",
    "\n",
    "class TextProcess(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X,y = None):\n",
    "        texts = []\n",
    "        for text in X:\n",
    "            text = text.lower()\n",
    "            text = re.sub('\\n', ' ', text)\n",
    "\n",
    "            text = re.sub('\\r', ' ', text)\n",
    "\n",
    "            text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', ' numero ', text)\n",
    "\n",
    "            text = re.sub(r'R\\$', ' ', text)\n",
    "            text = re.sub(r'\\W', ' ', text)\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "            \n",
    "            texts.append(text)\n",
    "        \n",
    "        return texts\n",
    "\n",
    "class StopwordsRemoval(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def remove_stopwords(self,text):\n",
    "        filtered_words = [word for word in text if word.lower() not in stopwords_pt]\n",
    "        text_clean = (\" \".join(filtered_words))\n",
    "        \n",
    "        return text_clean\n",
    "    \n",
    "    def transform(self, X, y =None):\n",
    "        text_process = list(map(lambda c:self.remove_stopwords(c), X))\n",
    "        text_transform = list(map(lambda x:''.join(x), text_process))\n",
    "        \n",
    "        return text_transform\n",
    "\n",
    "class Steam(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def steamming(self,text):\n",
    "        stemmer = RSLPStemmer()\n",
    "        return list(map(lambda x:stemmer.stem(x),[word for word in text.split()]))\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        text_transform = list(map(lambda x:self.steamming(x), X))\n",
    "        text_transform = list(map(lambda x: ''.join(x), text_transform))\n",
    "        \n",
    "        return text_transform\n",
    "            \n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T08:05:04.980827Z",
     "start_time": "2024-02-13T08:05:04.977751Z"
    }
   },
   "id": "e5bf6d11f2e75338"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe_preprocessing = Pipeline([\n",
    "    ('preprocess',TextProcess()),\n",
    "    ('stopwords', StopwordsRemoval()),\n",
    "    ('stemming', Steam())\n",
    "])\n",
    "\n",
    "text_processed = pipe_preprocessing.fit_transform(df_review['comment'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T10:41:19.657424Z",
     "start_time": "2024-02-13T10:41:19.650324Z"
    }
   },
   "id": "92ba80eb459a1f99"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vectorization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cccd81634a6a70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Text Processing Pipeline started')\n",
    "vectorizer = CountVectorizer(binary = True, max_features= 5000, stop_words= stopwords_pt)\n",
    "X = vectorizer.fit_transform(text_processed).toarray()\n",
    "\n",
    "y = df_review['label'].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.8, random_state =1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-13T10:41:19.652043Z"
    }
   },
   "id": "f12537069d59f213"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42ff3386e62d5c29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def matching_criteria(y_true, y_pred):\n",
    "    print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "    print(\"\\nROC, AUC:\", roc_auc_score(y_true, y_pred))\n",
    "    print(\"\\nF1-Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
    "    print(\"\\nIts Corresponding Confusion Matrix:\")\n",
    "    sns.heatmap(confusion_matrix(y_true, y_pred), annot=True)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-13T10:41:19.655631Z"
    }
   },
   "id": "527bac485b64f56c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def model_outcome(X_train,y_train, X_test, y_test):\n",
    "    models = []\n",
    "    models.append(('Logistic Regression', LogisticRegression()))\n",
    "    models.append(('Decision Trees', DecisionTreeClassifier()))\n",
    "    models.append(('Naive Bayes', GaussianNB()))\n",
    "    models.append(('SVM', SVC()))\n",
    "    models.append(('Random Forest', RandomForestClassifier()))\n",
    "\n",
    "    result = pd.DataFrame(columns = ['Model','Accuracy for Training','Accuracy for Testing','Std'])\n",
    "    for index,model in enumerate(models):\n",
    "        kfold = StratifiedKFold(n_splits = 5)\n",
    "        cross_val_result = cross_val_score(model[1], X_train,y_train, cv = kfold)\n",
    "\n",
    "        # training the model\n",
    "        model[1].fit(X_train,y_train)\n",
    "        predictions = model[1].predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "        result.loc[index,'Model'] = model[0]\n",
    "        result.loc[index,'Accuracy for Training'] = cross_val_result.mean()\n",
    "        result.loc[index,'Accuracy for Testing'] = test_accuracy\n",
    "        result.loc[index,'Std'] = cross_val_result.std()\n",
    "\n",
    "\n",
    "    return result\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-13T10:41:19.657348Z"
    }
   },
   "id": "e47f8f5277ca9d39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_outcome(X_train,y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T10:41:19.659480Z",
     "start_time": "2024-02-13T10:41:19.659219Z"
    }
   },
   "id": "61e28d85044fbd33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9ac0c40cc3e591df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
